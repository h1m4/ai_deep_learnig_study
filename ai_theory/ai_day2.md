# 신경망

* 신경망 : 머신러닝의 모델 구현 방법 중 하나. 뇌의 작동원리를 본 따 만든 것으로 수많은 신경 세포가 모여 뇌를 구성하는 것 처럼 신경 세포에 해당하는 `노드`로 연결해 만들어진 네트워크이다. 신경세포의 연결 관계를 `연결 가중치`라는 것을 통해 나타낸다.

## 신경망의 계층구조

| 신경망 | 계층구조 |
|---|:---:|:---:|
| 단층 신경망  | 입력층 - 출력층 |
| 다층 신경망 | 입력층 - 은닉층(들) - 출력층 |

* 입력층 : 노드들은 들어온 신호를 그대로 다음 노드로 전달하기만 한다.
* 출력층 : 신경망의 최종 결과값을 출력한다.
* 은닉층 : 신경망의 외부에서는 여기에 직접 접근할 수 없다. 계산은 이곳에서 이루어진다.

* `가중합 계산식 : Wx + b `
  * W : 각 행마다의 은닉 노드들의 가중치들이 배치된 행렬
  * b :  노드의 바이어스 벡터
  * x : 입력 신호 벡터

* 선형함수를 은닉노드들의 활성함수로 사용하면 은닉층을 추가한 효과가 없어진다. 즉, 수학적으로 단층 신경망이 된다.

## 신경망의 지도학습

* 지도학습의 순서
1. 신경망의 가중치를 적당한 값으로 초기화
2. `{입력, 정답}` 중에서 입력과 결과를 얻어 정답과 비교해 오차를 계산한다.
3. 오차가 줄어들도록 가중치 조절
4. 위 과정을 몇 번 반복

여기에서 전체 데이터를 재학습 시키는 과정이 존재하는 이유는 학습은 과정을 반복하면서 정답을 찾아내는 알고리즘이기 때문이다. 여기서 전체 데이터를 한 번 씩 전부 학습시킨 횟수를 `epoch`라고 한다.

## 가중치의 계산

* SGD : 하나의 학습 데이터마다 오차를 계산해 신경망의 가중치를 바로 조절한다. 그러므로 신경망이 성능이 들쑥날쑥 변하면서 갱신된다.

* 배치 : 모든 학습 데이터가 오차에 관해 가중치 갱신값을 계산한 후 이들의 평균값으로 가중치를 한 번 갱신하는 방법이다.

* 미니배치 : SGD방식과 배치 방식을 합친 방식. 전체 학습 데이터에서 일부 데이터만 골라 배치 방식으로 학습시킨 후, 이 값들의 평균으로 가중치를 갱신하는 방법.

<br>

* SGD 방식 구현

```matlab

function W = DeltaSGD(W, X, D)
  alpha = 0.9;
N = 4;
for k = 1:N
  x = X(k, :);
  d = D(k);

  v = W * x;
  y = Sigmoid(v);

  e = d - y;
  delta = y * (1-y) * e;

  dW = alpha * delta * x;

  W(1) = W(1) + dW(1);
  W(2) = W(2) + dW(2);
  W(3) = W(3) + dW(3);

  end

end
```

 * 배치 방식의 구현

 ```matlab
function W = DeltaBatch(W, X, D);
  alpha = 0.9;
    dWsum = zero(3, 1);

  N = 4;
  for k = 1:N
    x = X(k, :);
    d = D(k);

    v = W*x;
    y = Sigmoid(v);

    e = e - y;
    delta = y * (1 - y) * e;
    dW = alpha * delta * xl

    dWsum = dWsum + dW;
  end
  dWavg = dWsum / N;

  W(1) = W(1) + dWavg(1);
  W(2) = W(2) + dWavg(2);
  W(3) = W(3) + dWavg(3);  
end
```

SGD방식이 배치 방식보다 학습오차가 빨리 줄어든다.

## 단층 신경망의 한계

단층 신경망은 선형 분리 가능한 문제만 풀 수 있다. 단층 신경망은 입려 데이터의 공간을 선형 분리하는 모델이기 때문에 특정한 모델에 밖에 적용할 수 밖에 없다.
